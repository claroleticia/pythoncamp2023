{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "## M Leticia Claro\n",
    "- Go to: https://www.presidency.ucsb.edu/documents/app-categories/presidential/spoken-addressesand- remarks\n",
    "- Create a csv file with the following information for each spoken address given by President Biden since he became president on 2021-01-20:\n",
    "    - Date of spoken address\n",
    "    - Title\n",
    "    - Full text of address or remarks\n",
    "    - Citation/footnote (if one exists)\n",
    "- Remember, be polite and sleep after accessing each individual document page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directory to save the cvs file \n",
    "os.chdir(\"/Users/maria/Documents/GitHub/pythoncamp2023/HW\") # change it if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "web_address = 'https://www.presidency.ucsb.edu/documents/app-categories/presidential/spoken-addresses-and-remarks?items_per_page=60&page='\n",
    "web_aux = 'https://www.presidency.ucsb.edu'\n",
    "date_start = datetime.datetime(2021, 1, 20, 0 ,0) # date in which Biden's term start\n",
    "speech={}\n",
    "page_number = 0\n",
    "total_page = 534 # 533 + 1\n",
    "with open('pres_speech.csv','w') as f:\n",
    "    #w = csv.DictWriter(f, fieldnames=(\"date\",\"title\",\"content\",\"citation\")) # define the columns name\n",
    "    w = csv.DictWriter(f, fieldnames=(\"date\",\"title\",\"content\",\"citation\",\"footnote\")) # define the columns name\n",
    "    w.writeheader()\n",
    "    for i in range(0,30): # number of pages to navigate (could be total of pages, should stops anyway when date is less than Biden's first)\n",
    "        broken = False\n",
    "        try:\n",
    "            web_page = urllib.request.urlopen(web_address + str(page_number))\n",
    "            soup = BeautifulSoup(web_page.read())\n",
    "            all_date_speech = soup.find_all(class_=re.compile(\"col-sm-8\"))\n",
    "            for i in range(0,10): # number of posts per page to get (can be len(all_date_speech))\n",
    "                print(speech)\n",
    "                date_speech_i = all_date_speech[i].find_all('a')\n",
    "                speech['date']= all_date_speech[i].find('span').attrs['content'] # get the post's date within the attribute content \n",
    "                speech['date']= speech['date'][:10] #cut the hours from the string date\n",
    "                speech['date'] = datetime.datetime.strptime(speech['date'], '%Y-%m-%d')\n",
    "                if speech['date']<= date_start:\n",
    "                    broken = True\n",
    "                    break #breaks the 2nd for loop\n",
    "\n",
    "                inner_page_url = web_aux + all_date_speech[i].find('a').attrs['href']                    \n",
    "                inner_page = urllib.request.urlopen(inner_page_url)\n",
    "                #print(inner_page)\n",
    "                inner_soup = BeautifulSoup(inner_page.read())\n",
    "                speech['title'] = inner_soup.find('h1').text\n",
    "                speech['content'] = inner_soup.find('div', {'class':'field-docs-content'}).text\n",
    "                speech['footnote'] = inner_soup.find('div', {'class':'field-docs-footnote'}).text if inner_soup.find('div', {'class':'field-docs-footnote'}) else ''\n",
    "                speech['citation'] = inner_soup.find('div', {'class':'field-prez-document-citation'}).text if inner_soup.find('div', {'class':'field-prez-document-citation'}) else ''\n",
    "                w.writerow(speech)\n",
    "                time.sleep(random.uniform(1,5))\n",
    "            page_number += 1                    \n",
    "            if broken:\n",
    "                # break the 1st for loop\n",
    "                break     \n",
    "        except:\n",
    "            continue\n",
    "            #  \n",
    "            #    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "The current script does everthing in the list. However, I'm only running it for the 10 first posts in each page. Two reasons: 1) goes faster 2) when running for the 60 entries in each page I get a strange output (from March 15 to March 3 it keeps looping forever within these entries). I checked for a series of possibilities like missing tag, or missing parameters but without success.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
